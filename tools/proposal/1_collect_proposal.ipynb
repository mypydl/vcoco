{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mmcv import imread\n",
    "from mmengine import dump, load\n",
    "\n",
    "from utils import box_xywh2xyxy, box_xyxy2xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = load('../../annotations/image_info_train.json')\n",
    "test_img  = load('../../annotations/image_info_test.json')\n",
    "\n",
    "train_img_root = '../../images/train/'\n",
    "test_img_root = '../../images/test/'\n",
    "\n",
    "ins_categories = load('../../configs/ins_categories.json')\n",
    "coco_ins_label2cat = {i: cat['id'] for i, cat in enumerate(ins_categories)}\n",
    "coco_ins_cat2label = {cat['id']: i for i, cat in enumerate(ins_categories)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "palette = np.asarray([\n",
    "    (220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230), (106, 0, 228),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 70), (0, 0, 192), (250, 170, 30),\n",
    "    (100, 170, 30), (220, 220, 0), (175, 116, 175), (250, 0, 30),\n",
    "    (165, 42, 42), (255, 77, 255), (0, 226, 252), (182, 182, 255),\n",
    "    (0, 82, 0), (120, 166, 157), (110, 76, 0), (174, 57, 255),\n",
    "    (199, 100, 0), (72, 0, 118), (255, 179, 240), (0, 125, 92),\n",
    "    (209, 0, 151), (188, 208, 182), (0, 220, 176), (255, 99, 164),\n",
    "    (92, 0, 73), (133, 129, 255), (78, 180, 255), (0, 228, 0),\n",
    "    (174, 255, 243), (45, 89, 255), (134, 134, 103), (145, 148, 174),\n",
    "    (255, 208, 186), (197, 226, 255), (171, 134, 1), (109, 63, 54),\n",
    "    (207, 138, 255), (151, 0, 95), (9, 80, 61), (84, 105, 51),\n",
    "    (74, 65, 105), (166, 196, 102), (208, 195, 210), (255, 109, 65),\n",
    "    (0, 143, 149), (179, 0, 194), (209, 99, 106), (5, 121, 0),\n",
    "    (227, 255, 205), (147, 186, 208), (153, 69, 1), (3, 95, 161),\n",
    "    (163, 255, 0), (119, 0, 170), (0, 182, 199), (0, 165, 120),\n",
    "    (183, 130, 88), (95, 32, 0), (130, 114, 135), (110, 129, 133),\n",
    "    (166, 74, 118), (219, 142, 185), (79, 210, 114), (178, 90, 62),\n",
    "    (65, 70, 15), (127, 167, 115), (59, 105, 106), (142, 108, 45),\n",
    "    (196, 172, 0), (95, 54, 80), (128, 76, 255), (201, 57, 1),\n",
    "    (246, 0, 122), (191, 162, 208)], dtype=float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box(box, ax, info: dict = {}):\n",
    "    x, y, w, h = box\n",
    "\n",
    "    edgecolor = info.get('edgecolor', 'green')\n",
    "    name = info.get('name', '')\n",
    "\n",
    "    # ax.text(x0, y0, name, fontdict=font)\n",
    "    ax.text(x, y, name)\n",
    "    # 底色\n",
    "    ax.add_patch(plt.Rectangle((x, y), w, h, edgecolor='white', facecolor=(0,0,0,0), lw=2))\n",
    "    # 类别颜色\n",
    "    ax.add_patch(plt.Rectangle((x, y), w, h, edgecolor=edgecolor, facecolor=(0,0,0,0), lw=1))\n",
    "\n",
    "def watch_ins_proposal(proposal: dict, img_path: str, with_name: bool = True):\n",
    "    image = imread(img_path, channel_order='rgb')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(os.path.basename(img_path))\n",
    "    ax.axis('off')\n",
    "    bboxes = proposal['instances']['bboxes']\n",
    "    labels = proposal['instances']['labels']\n",
    "    for box, label in zip(bboxes, labels):\n",
    "        cat = coco_ins_label2cat[label]\n",
    "        info = dict(edgecolor=palette[label])\n",
    "        if with_name:\n",
    "            info['name'] = ins_categories[cat]['name']\n",
    "        show_box(box, ax, info=info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_mmdet_proposal(ins_pred: list, coco_img: dict, score_thr: float = 0.1):\n",
    "    \"\"\"从mmdet的预测转换\"\"\"\n",
    "    id2filename = {item['id']: item['file_name'] for item in coco_img['images']}\n",
    "\n",
    "    num_valid = 0\n",
    "    ins_proposals = defaultdict(lambda:{'bboxes': [], 'labels': [], 'scores': []})\n",
    "    for ins in tqdm(ins_pred):\n",
    "        if ins['score'] < score_thr:\n",
    "            continue\n",
    "        num_valid += 1\n",
    "        img_name = id2filename[ins['image_id']]\n",
    "        ins_proposals[img_name]['bboxes'].append(box_xywh2xyxy(ins['bbox']))\n",
    "        ins_proposals[img_name]['labels'].append(ins['category_id'])\n",
    "        ins_proposals[img_name]['scores'].append(ins['score'      ])\n",
    "    print('num valid:', num_valid)\n",
    "\n",
    "    total_proposals = {}\n",
    "    for filename, props in ins_proposals.items():\n",
    "        labels = props['labels']\n",
    "        if coco_ins_cat2label is not None:\n",
    "            labels = [coco_ins_cat2label[i] for i in labels]\n",
    "        ins_props = {\n",
    "            'bboxes': np.float32(props['bboxes']).round(0),\n",
    "            'scores': np.float32(props['scores']).round(3),\n",
    "            'labels': np.int64(labels),\n",
    "            'ids'   : np.arange(len(labels))  # 单张图内id\n",
    "        }\n",
    "\n",
    "        total_proposals[filename] = {'instances': ins_props}\n",
    "    return total_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_scg_proposal(root, ins_label_2_id_map: dict = None, \n",
    "                     score_thr: float = 0.1, human_id: int = 0):\n",
    "    \"\"\"从SCG系列（SCG, ViPLO, UPT）的proposal转换\"\"\"\n",
    "    total_proposals = {}\n",
    "    for filename in tqdm(os.listdir(root)):\n",
    "        props = load(os.path.join(root, filename))\n",
    "        img_name = filename.replace('.json', '.jpg')\n",
    "\n",
    "        labels = props['labels']\n",
    "        if ins_label_2_id_map is not None:\n",
    "            labels = [ins_label_2_id_map[i] for i in labels]\n",
    "\n",
    "        bboxes = np.float32(props['boxes' ]).round(0)  # xyxy\n",
    "        scores = np.float32(props['scores']).round(3)\n",
    "        labels = np.int64(labels)\n",
    "\n",
    "        keep = scores > score_thr\n",
    "        keep_human = keep[labels == human_id]\n",
    "\n",
    "        ins_props = {\n",
    "            'bboxes': bboxes[keep],\n",
    "            'scores': scores[keep],\n",
    "            'labels': labels[keep],\n",
    "            'ids'   : np.arange(keep.sum())  # 单张图内id\n",
    "        }\n",
    "\n",
    "        if 'human_joints' in props:\n",
    "            points = np.float32(props['human_joints']\n",
    "                                ).round(0).reshape(-1, 17, 2)\n",
    "            scores = np.float32(props['human_joints_score']\n",
    "                                ).round(3).reshape(-1, 17)\n",
    "            pose_props = {\n",
    "                'keypoints' : points[keep_human],\n",
    "                'scores'    : scores[keep_human],\n",
    "                'tgt_ins_id': np.where(ins_props['labels']==human_id)[0]\n",
    "            }\n",
    "\n",
    "            total_proposals[img_name] = {\n",
    "                'instances'       : ins_props, \n",
    "                'person_keypoints': pose_props\n",
    "            }\n",
    "        else:\n",
    "            total_proposals[img_name] = {'instances': ins_props}\n",
    "    return total_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_ins_ann2proposal(coco_ins: COCO):\n",
    "    proposals = dict()\n",
    "    for img_id in tqdm(coco_ins.getImgIds()):\n",
    "        img_info = coco_ins.loadImgs(img_id)[0]\n",
    "        ins_anns = coco_ins.loadAnns(sorted(coco_ins.getAnnIds(img_id)))\n",
    "\n",
    "        bboxes, labels = [], []\n",
    "        for ann in ins_anns:\n",
    "            bboxes.append(box_xywh2xyxy(ann['bbox']))\n",
    "            labels.append(coco_ins_cat2label[ann['category_id']])\n",
    "\n",
    "        proposals[img_info['file_name']] = {\n",
    "            'instances': {\n",
    "                'bboxes': np.float32(bboxes),\n",
    "                'scores': np.ones_like(labels, dtype=np.float32),\n",
    "                'labels': np.int64(labels),\n",
    "                'ids'   : np.arange(len(labels))  # 单张图内id\n",
    "            }\n",
    "        }\n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuhao/.conda/envs/torch2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wuhao/.conda/envs/torch2/lib/python3.9/site-packages/colossalai/kernel/cuda_native/mha/flash_attn_2.py:21: UserWarning: FlashAttention only supports Ampere GPUs or newer.\n",
      "  warnings.warn(\"FlashAttention only supports Ampere GPUs or newer.\")\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0)\n",
      "    Python  3.9.18 (you have 3.9.18)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "from mmengine.structures import InstanceData\n",
    "from mmpose.structures import PoseDataSample\n",
    "from mmpose.visualization import PoseLocalVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1,\n",
      "  'keypoints': ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',\n",
      "                'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
      "                'left_wrist', 'right_wrist', 'left_hip', 'right_hip',\n",
      "                'left_knee', 'right_knee', 'left_ankle', 'right_ankle'],\n",
      "  'name': 'person',\n",
      "  'skeleton': [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12],\n",
      "               [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3],\n",
      "               [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]],\n",
      "  'supercategory': 'person'}]\n"
     ]
    }
   ],
   "source": [
    "pose_categories = load('../../configs/pose_categories.json')\n",
    "pprint(pose_categories, compact=True)\n",
    "\n",
    "dataset_meta = {'skeleton_links': pose_categories[0]['skeleton']}\n",
    "pose_local_visualizer = PoseLocalVisualizer(\n",
    "    link_color=tuple((255, 0, 0)) * len(dataset_meta['skeleton_links']),\n",
    "    line_width=4)\n",
    "pose_local_visualizer.set_dataset_meta(dataset_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_pose_proposal(proposal: dict, img_path: str):\n",
    "    visualizer = deepcopy(pose_local_visualizer)\n",
    "    image = imread(img_path, channel_order='rgb')\n",
    "    data = PoseDataSample()\n",
    "    keypoints = np.array(proposal['person_keypoints']['keypoints']).reshape(-1, 17, 3)\n",
    "    data.gt_instances = InstanceData(keypoints=keypoints)\n",
    "    vis_result = visualizer.add_datasample('image', image, data, draw_pred=False)\n",
    "    plt.imshow(vis_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_person_from_proposal(ins_props: dict, coco_img: dict):\n",
    "    \"\"\"挑出“人”实例，用于姿态估计\"\"\"\n",
    "    filename2id = {item['file_name']: item['id'] for item in coco_img['images']}\n",
    "\n",
    "    human_ins = []\n",
    "    imgs_wo_human = []\n",
    "\n",
    "    for filename, prop in tqdm(ins_props.items()):\n",
    "        prop = prop['instances']\n",
    "        image_id = filename2id[filename]\n",
    "        wo_human = True\n",
    "        for label, bbox, score, id in zip(prop['labels'], prop['bboxes'], \n",
    "                                          prop['scores'], prop['ids'   ]):\n",
    "            if label == 0:\n",
    "                wo_human = False\n",
    "                human_ins.append({\n",
    "                    'image_id'   : image_id,\n",
    "                    'bbox'       : box_xyxy2xywh(bbox),\n",
    "                    'score'      : score,\n",
    "                    'category_id': 1,\n",
    "                    'id'         : id\n",
    "                })\n",
    "        if wo_human:\n",
    "            imgs_wo_human.append(image_id)\n",
    "\n",
    "    print('num person:', len(human_ins))\n",
    "    print('num image wo person:', len(imgs_wo_human))\n",
    "    return human_ins, imgs_wo_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并各种类型的proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pose_to_prop(proposals: dict, pose_pred: list, coco_img: dict) -> dict:\n",
    "    id2filename = {item['id']: item['file_name'] for item in coco_img['images']}\n",
    "\n",
    "    pose_proposals = defaultdict(list)\n",
    "    for pose in tqdm(pose_pred):\n",
    "        img_name = id2filename[pose['image_id']]\n",
    "        pose_proposals[img_name].append(pose['keypoints'])\n",
    "    pose_proposals = dict(pose_proposals)\n",
    "\n",
    "    print('num image:', len(set(proposals.keys())))\n",
    "    print('num image wo pose prop:', \n",
    "          len(set(proposals.keys()) ^ set(pose_proposals.keys())))\n",
    "\n",
    "    total_proposals = deepcopy(proposals)\n",
    "    for img_name, props in total_proposals.items():\n",
    "        if img_name not in pose_proposals:\n",
    "            # 没有person预测，也就没有pose预测\n",
    "            poses = np.zeros((0, 17, 3))\n",
    "        else:\n",
    "            poses = pose_proposals[img_name]\n",
    "            poses = np.array(poses, dtype=np.float32).reshape(-1, 17, 3)\n",
    "        props['person_keypoints'] = {\n",
    "            'keypoints': poses[..., :-1],\n",
    "            'scores'   : poses[...,  -1],\n",
    "            'tgt_ins_id': np.where(proposals[img_name]['instances']['labels']==0)[0]\n",
    "        }\n",
    "    return total_proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实际转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FasterRCNN(SCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_root = '../../proposals/SCG/'\n",
    "train_total_prop_path = os.path.join(proposal_root, 'proposal_scg_train.pkl')\n",
    "test_total_prop_path  = os.path.join(proposal_root, 'proposal_scg_test.pkl')\n",
    "train_ins_prop_root   = os.path.join(proposal_root, 'trainval')\n",
    "test_ins_prop_root    = os.path.join(proposal_root, 'test')\n",
    "train_pose_prop_path  = os.path.join(proposal_root, 'body2d_vcoco-train_scg.keypoints.json')\n",
    "test_pose_prop_path   = os.path.join(proposal_root, 'body2d_vcoco-test_scg.keypoints.json')\n",
    "train_person_path     = os.path.join(proposal_root, 'train_person.json')\n",
    "test_person_path      = os.path.join(proposal_root, 'test_person.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4969/4969 [00:00<00:00, 5261.58it/s]\n",
      "100%|██████████| 4532/4532 [00:00<00:00, 5567.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# 转换proposal格式\n",
    "scg_ins_map = {i: i-1 for i in range(1, 81)}\n",
    "train_proposals = cvt_scg_proposal(train_ins_prop_root, scg_ins_map, score_thr=0.1)\n",
    "test_proposals  = cvt_scg_proposal( test_ins_prop_root, scg_ins_map, score_thr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_proposals = load(train_total_prop_path)\n",
    "# test_proposals  = load( test_total_prop_path)\n",
    "# len(train_proposals), len(test_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': {'bboxes': array([[257., 106., 630., 519.],\n",
       "         [ 12.,  22., 373., 535.],\n",
       "         [151., 155., 262., 406.],\n",
       "         [245.,   3., 510., 327.],\n",
       "         [162., 154., 322., 386.],\n",
       "         [  1., 320.,  36., 534.],\n",
       "         [160., 141., 251., 397.],\n",
       "         [385., 224., 443., 285.],\n",
       "         [248., 376., 287., 402.],\n",
       "         [171., 119., 426., 498.],\n",
       "         [ 39.,   0., 447., 439.],\n",
       "         [172., 136., 254., 276.],\n",
       "         [ 47.,  29., 275., 386.],\n",
       "         [240., 380., 323., 535.],\n",
       "         [300., 107., 604., 353.],\n",
       "         [  2.,   3., 115., 294.],\n",
       "         [142.,   7., 496., 455.],\n",
       "         [389., 374., 452., 475.]], dtype=float32),\n",
       "  'scores': array([0.998, 0.98 , 0.946, 0.763, 0.489, 0.464, 0.412, 0.409, 0.29 ,\n",
       "         0.207, 0.192, 0.172, 0.158, 0.151, 0.141, 0.132, 0.129, 0.102],\n",
       "        dtype=float32),\n",
       "  'labels': array([ 0,  0, 27, 25, 76,  0, 43, 56, 76, 27, 25, 27,  0, 26,  0, 56,  0,\n",
       "         27]),\n",
       "  'ids': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17])}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_proposals['COCO_train2014_000000000165.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### person_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4969/4969 [00:00<00:00, 16145.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 47187\n",
      "num image wo person: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4532/4532 [00:00<00:00, 17777.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 44674\n",
      "num image wo person: 2\n"
     ]
    }
   ],
   "source": [
    "# 提取仅含“人”的实例\n",
    "train_person, train_imgs_wo_human = extract_person_from_proposal(train_proposals, train_img)\n",
    "test_person ,  test_imgs_wo_human = extract_person_from_proposal( test_proposals,  test_img)\n",
    "dump(train_person, train_person_path)\n",
    "dump( test_person,  test_person_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59010, 55569)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_person = load(train_person_path)\n",
    "# test_person  = load( test_person_path)\n",
    "# len(train_person), len(test_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 27562,\n",
       " 'bbox': [577.0, 270.0, 8.0, 18.0],\n",
       " 'score': 0.316,\n",
       " 'category_id': 1,\n",
       " 'id': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_person[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取姿态估计结果\n",
    "train_pose = load(train_pose_prop_path)\n",
    "test_pose  = load( test_pose_prop_path)\n",
    "assert len(train_pose) == len(train_person), f'{len(train_pose)} != {len(train_person)}'\n",
    "assert len( test_pose) == len( test_person), f'{len( test_pose)} != {len( test_person)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47187/47187 [00:00<00:00, 915920.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image: 4969\n",
      "num image wo pose prop: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44674/44674 [00:00<00:00, 1176292.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image: 4532\n",
      "num image wo pose prop: 2\n"
     ]
    }
   ],
   "source": [
    "# 转换成keypoints_proposal\n",
    "train_proposals = merge_pose_to_prop(train_proposals, train_pose, train_img)\n",
    "test_proposals  = merge_pose_to_prop( test_proposals,  test_pose,  test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(train_proposals, train_total_prop_path)\n",
    "dump( test_proposals,  test_total_prop_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_root = '../../proposals/UPT/'\n",
    "train_total_prop_path = os.path.join(proposal_root, 'proposal_upt_train.pkl')\n",
    "test_total_prop_path  = os.path.join(proposal_root, 'proposal_upt_test.pkl')\n",
    "train_ins_prop_path   = os.path.join(proposal_root, 'ins_vcoco-train_upt.bbox.json')\n",
    "test_ins_prop_path    = os.path.join(proposal_root, 'ins_vcoco-test_upt.bbox.json')\n",
    "train_pose_prop_path  = os.path.join(proposal_root, 'body2d_vcoco-train_upt.keypoints.json')\n",
    "test_pose_prop_path   = os.path.join(proposal_root, 'body2d_vcoco-test_upt.keypoints.json')\n",
    "train_person_path     = os.path.join(proposal_root, 'train_person.json')\n",
    "test_person_path      = os.path.join(proposal_root, 'test_person.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ins_props = load(train_ins_prop_path)\n",
    "test_ins_props  = load( test_ins_prop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 165,\n",
       " 'bbox': [598.669921875, 354.3212890625, 41.21551513671875, 112.9805908203125],\n",
       " 'score': 0.01862606778740883,\n",
       " 'category_id': 62}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ins_props[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540000/540000 [00:00<00:00, 2733718.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num valid: 47350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494600/494600 [00:00<00:00, 2075272.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num valid: 43307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 转换proposal格式\n",
    "train_proposals = cvt_mmdet_proposal(train_ins_props, train_img, score_thr=0.1)\n",
    "test_proposals  = cvt_mmdet_proposal( test_ins_props,  test_img, score_thr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 4946)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_proposals = load(train_total_prop_path)\n",
    "# test_proposals  = load( test_total_prop_path)\n",
    "# len(train_proposals), len(test_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': {'bboxes': array([[256., 108., 639., 530.],\n",
       "         [  6.,  28., 365., 530.],\n",
       "         [ 61., 122., 384., 407.],\n",
       "         [154., 125., 365., 402.],\n",
       "         [159., 124., 367., 320.],\n",
       "         [163., 175., 256., 400.]], dtype=float32),\n",
       "  'scores': array([0.994, 0.992, 0.97 , 0.784, 0.208, 0.206], dtype=float32),\n",
       "  'labels': array([ 0,  0, 76, 76, 76, 27]),\n",
       "  'ids': array([0, 1, 2, 3, 4, 5])}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_proposals['COCO_train2014_000000000165.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### person_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5400/5400 [00:00<00:00, 86707.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 16318\n",
      "num image wo person: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4946/4946 [00:00<00:00, 5611.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 15495\n",
      "num image wo person: 3\n"
     ]
    }
   ],
   "source": [
    "# 提取仅含“人”的实例\n",
    "train_person, train_imgs_wo_human = extract_person_from_proposal(train_proposals, train_img)\n",
    "test_person ,  test_imgs_wo_human = extract_person_from_proposal( test_proposals,  test_img)\n",
    "dump(train_person, train_person_path)\n",
    "dump( test_person,  test_person_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_person = load(train_person_path)\n",
    "# test_person  = load( test_person_path)\n",
    "# len(train_person), len(test_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 165,\n",
       " 'bbox': [256.0, 108.0, 383.0, 422.0],\n",
       " 'score': 0.994,\n",
       " 'category_id': 1,\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_person[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取姿态估计结果\n",
    "train_pose = load(train_pose_prop_path)\n",
    "test_pose  = load( test_pose_prop_path)\n",
    "assert len(train_pose) == len(train_person), f'{len(train_pose)} != {len(train_person)}'\n",
    "assert len( test_pose) == len( test_person), f'{len( test_pose)} != {len( test_person)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16318/16318 [00:00<00:00, 615923.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image: 5400\n",
      "num image wo pose prop: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15495/15495 [00:00<00:00, 1632687.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image: 4946\n",
      "num image wo pose prop: 3\n"
     ]
    }
   ],
   "source": [
    "# 转换成keypoints_proposal\n",
    "train_proposals = merge_pose_to_prop(train_proposals, train_pose, train_img)\n",
    "test_proposals  = merge_pose_to_prop( test_proposals,  test_pose,  test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(train_proposals, train_total_prop_path)\n",
    "dump( test_proposals,  test_total_prop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
